Univariate linear regression
=============================

=======================
Example: Housing prices
=======================

.. figure:: img/univariate_lr_ex.png
    :align: center
    :scale: 40%


=========
Process
=========

.. figure:: img/univariate_lr_process.png
    :align: center
    :scale: 40%


==============================
Notation of training set
==============================

.. figure:: img/notation_of_training_set.png
    :align: center
    :scale: 40%


| m = The number of training examples (samples)
| x's = Input variables (Features)
| y's = Output variables (Target variables)
| (x, y) = One training example
| (x\ :sub:`i`\, y\ :sub:`i`\) = ith training example


=======================
Hypothesis function
=======================

.. figure:: img/hypothesis_function.png
    :align: center
    :scale: 40%


====================
Cost function
====================

**Idea**

Choose ğœ½\ :sub:`0`\, ğœ½\ :sub:`1`\ so that â„\ :sub:`ğœƒ`\ (ğ‘¥) is close to ğ‘¦ for training samples.

**Examples**

.. figure:: img/cost_function_ex.png
    :align: center
    :scale: 50%


**Method**

Minimize the squared error function.

.. figure:: img/cost_function_equation.png
    :align: center
    :scale: 40%


==================
Gradient descent
==================

**Idea**
    * Make arbitrary function  ğ‘±(ğœ½\ :sub:`0`\, ğœ½\ :sub:`ğŸ`\)
    * Find (ğ¦ğ¢ğ§)â”¬(ğœ½\ :sub:`0`\, ğœ½\ :sub:`1`\)â¡ğ‘±(ğœ½\ :sub:`ğŸ`\, ğœ½\ :sub:`ğŸ`\)

**Process**
    * Start with some ğœ½\ :sub:`0`\, ğœ½\ :sub:`ğŸ`\
    * Keep changing ğœ½\ :sub:`0`\, ğœ½\ :sub:`ğŸ`\ to reduce ğ‰(ğœ½\ :sub:`0`\, ğœ½\ :sub:`ğŸ`\) until we hopefully end up at a minimum

**Types**
    * Batch gradient descent
        * Each step of gradient descent uses all the training set.
    * Stochastic gradient descent (SGD)
        * Each step of gradient descent uses partial of the training set called mini-batch.

**Algorithm**

.. figure:: img/gradient_descent_algorithm.png
    :align: center
    :scale: 20%


.. figure:: img/gradient_descent_condition.png
    :align: center
    :scale: 40%


Should be updated simultaneously!!

**Linear equation movement**

.. figure:: img/gradient_descent_move.png
    :align: center
    :scale: 40%


**Learning rate ğœ¶**

.. figure:: img/gradient_descent_learning_rate.png
    :align: center
    :scale: 40%


**Fixed learning rate ğœ¶**

.. figure:: img/gradient_descent_fixed_learning_rate.png
    :align: center
    :scale: 40%


**Local minimum problem**

.. figure:: img/local_minimum_problem.png
    :align: center
    :scale: 40%


**Final algorithm for the linear regression**

.. figure:: img/gradient_descent_algorithm_for_linear_regression.png
    :align: center
    :scale: 50%


ì´ ë¶€ë¶„ì€ ì¶”í›„ì— ë³´ì¶© í•„ìš” (ê³¼ì •)



**Reference**
    * https://www.coursera.org/learn/machine-learning
